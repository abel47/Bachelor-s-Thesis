{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import GenericUnivariateSelect\n",
    "\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "from library.MyBinaryRelevanceFeatureSelect import MyBinaryRelevanceFeatureSelect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MyBinaryRelevanceFeatureSelect():\n",
    "   \n",
    "#     def fit(self, X, y):\n",
    "        \n",
    "#         # I'm using a gaussian naive bayes base classifier\n",
    "#         self.BinaryRelevanceObject = BinaryRelevance(classifier = SVC(gamma= 'auto'), require_dense = [True, True])\n",
    "        \n",
    "#         # fitting the data\n",
    "#         self.BinaryRelevanceObject.fit(X, y)\n",
    "        \n",
    "#         #the classifiers for each label\n",
    "#         self.classifiers = self.BinaryRelevanceObject.classifiers_\n",
    "\n",
    "#         return self\n",
    "        \n",
    "# #     def partition(self):\n",
    "# #         return self.BinaryRelevanceObject.partition_#BinaryRelevanceObject\n",
    "    \n",
    "# #     def model_count(self):\n",
    "# #         return self.BinaryRelevanceObject.model_count_\n",
    "\n",
    "#     def predict(self, X, y=None):\n",
    "#         return self.BinaryRelevanceObject.predict(X)\n",
    "    \n",
    "# #     def feature_select(self, X, y):\n",
    "        \n",
    "# #         #features_selected = []\n",
    "\n",
    "# # #         X_new = SelectKBest(chi2, k=2)\n",
    "\n",
    "# # #         # the feature selecting\n",
    "# # #         X_new.fit(X, y)\n",
    "\n",
    "# # #         # save indices of the saved attributes\n",
    "# # #         selected_attributes_indices = X_new.get_support(indices = True)\n",
    "        \n",
    "# #         transformer = GenericUnivariateSelect(chi2, 'k_best', param=2)\n",
    "# #         X_new = transformer.fit_transform(X, y)\n",
    "# #         #X_new.shape\n",
    "# #         selected_attributes_indices = transformer.get_support(indices = True)\n",
    "        \n",
    "# #         return selected_attributes_indices\n",
    "    \n",
    "#     def feature_select(self, X, y, transformer):\n",
    "        \n",
    "#         #transformer = SelectKBest(chi2, k=2)\n",
    "#         transformer.fit(X, y)\n",
    "#         selected_attributes_indices = transformer.get_support(indices = True)\n",
    "        \n",
    "#         return selected_attributes_indices\n",
    "    \n",
    "#     def sets_of_selected_features(self, X, predictions, classifier, transformer ): #X is the df with the predictions\n",
    "#         selected_features_array = []\n",
    "\n",
    "#         for i in predictions:\n",
    "#             indices_features_selected = clf.feature_select(X, predictions[i], transformer)\n",
    "#             selected_features_array.append(indices_features_selected)\n",
    "    \n",
    "#         return selected_features_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making the dataset\n",
    "X, y = make_multilabel_classification(n_classes=6, n_labels=2,sparse = True, allow_unlabeled=False, random_state=1)\n",
    "\n",
    "#split in training and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "\n",
    "#intializing with the classifier class\n",
    "clf = MyBinaryRelevanceFeatureSelect()\n",
    "\n",
    "#fitting the data for training\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#sparse matrix\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "#make a dataframe\n",
    "x = pd.DataFrame(predictions.toarray())\n",
    "\n",
    "\n",
    "#the feature selection\n",
    "#x = clf.feature_select1(X_test,x[0],GenericUnivariateSelect(chi2, 'k_best', param=4))\n",
    "#SelectKBest(chi2, k=5)\n",
    "xx = clf.feature_select(X_test,x[0],SelectKBest(chi2, k=3))#[:]#array([ 1,  6, 14, 16, 19], dtype=int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<library.MyBinaryRelevanceFeatureSelect.MyBinaryRelevanceFeatureSelect at 0x1b02596fba8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 3, 16, 19], dtype=int64),\n",
       " array([17, 18, 19], dtype=int64),\n",
       " array([17, 18, 19], dtype=int64),\n",
       " array([ 2,  3, 19], dtype=int64),\n",
       " array([11, 18, 19], dtype=int64),\n",
       " array([17, 18, 19], dtype=int64)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.sets_of_selected_features(X_test,x,clf,SelectKBest(chi2, k=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 3, 16, 19], dtype=int64),\n",
       " array([17, 18, 19], dtype=int64),\n",
       " array([17, 18, 19], dtype=int64),\n",
       " array([ 2,  3, 19], dtype=int64),\n",
       " array([11, 18, 19], dtype=int64),\n",
       " array([17, 18, 19], dtype=int64)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = clf.sets_of_selected_features(X_test,x,clf,SelectKBest(chi2, k=3))\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{19}\n",
      "{2, 3, 11, 16, 17, 18, 19}\n",
      "set()\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#type(x[0])\n",
    "\n",
    "# np.intersect1d(x)\n",
    "print(set(arr[0]).intersection(*arr))\n",
    "print(set(arr[0]).union(*arr))\n",
    "print(set(arr[0]).difference(*arr))\n",
    "print(set(arr[0]).difference_update(*arr))\n",
    "\n",
    "\n",
    "# for i in x:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23232323232323232"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import hamming_loss\n",
    "\n",
    "hamming_loss(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
